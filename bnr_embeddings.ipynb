{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings \n",
    "from langchain.text_splitter import CharacterTextSplitter \n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate\n",
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Import PyPDF2\n",
    "import PyPDF2\n",
    "import numpy as np \n",
    "import torch\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"dslim/bert-base-NER\"\n",
    "\n",
    "# load the tokenizer from huggingface\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id\n",
    ")\n",
    "# load the NER model from huggingface\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id\n",
    ")\n",
    "# load the tokenizer and model into a NER pipeline\n",
    "nlp = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"max\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# Load openai api key \n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Load Pinecone API key \n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "# Load pinecode api env \n",
    "pinecone_api_env = os.environ.get('PINECONE_API_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation destinations for someone who likes to eat dessert?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"dessert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France - Home of the famous patisseries such as Laduree with its signature macarons and Pierre Herme's decadent cakes.\n",
      "\n",
      "2. Tokyo, Japan - With an ever-growing range of interesting and complex desserts from fluffy souffles to mochi ice cream, Tokyo is a great destination for dessert lovers.\n",
      "\n",
      "3. New York City, United States - A seemingly never-ending array of dessert spots, from the classic cronuts to inventive ice cream flavors, NYC has something for everyone.\n",
      "\n",
      "4. Milan, Italy - An embarrassment of riches when it comes to desserts, Milan offers traditional favorites like gelato and Tiramisu, as well as modern takes on traditional cakes and pastries.\n",
      "\n",
      "5. Vienna, Austria - Famous for its Sachertorte and apple strudel, Vienna has a deep history of decadent desserts to explore.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"dessert\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Costa Rica - known for its delicious tropical fruits such as papayas, pineapples, and bananas.\n",
      "\n",
      "2. India - expore the diverse culinary traditions of India and you'll find an abundance of sweet, juicy tropical fruits like Mangos and Guavas.\n",
      "\n",
      "3. Brazil - taste all the exotic fruits such as CupuaÃ§u, Cherimoyas, and Tomates de Arvobia.\n",
      "\n",
      "4. Thailand - enjoy an array of amazing fruits like mangosteen, Thai dragonfruit, and rambutan.\n",
      "\n",
      "5. Hawaii - savor the sweet taste of fresh pineapples, starfruit, and lychees.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"fruit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (2.4.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from google-search-results) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in some tools to use\n",
    "\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"...\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's initialize an agent with:\n",
    "# 1. The tools\n",
    "# 2. The language model\n",
    "# 3. The type of agent we want to use.\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Y Combinator is a venture capital firm, so I need to research their leaders and successful companies.\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for a website that lists Y Combinator information\n",
      "Action: Search\n",
      "Action Input: Ycombinator website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. ... Twice a year we invest $500,000 per company in a large number of startups. We work ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The website looks like it has the information I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Maybe I can find the website on a venture capital resource site\n",
      "Action: Search\n",
      "Action Input: venture capital website Ycombinator\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. Twice a year we invest $500,000 per company in a large number of startups.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the right resource\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should check Y Combinator's own website\n",
      "Action: Search\n",
      "Action Input: Ycombinator website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. ... Twice a year we invest $500,000 per company in a large number of startups. We work ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the resource I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership, successful Ycombinator companies\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Maybe a search for the leadership page of Y Combinator will provide what I'm looking for\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership page\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFounder & CEO Aaron King expertly built Snapdocs through volatile market conditions and with minimal outside funding into the mortgage industry's leading ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The leadership page looks to contain what I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGarry Tan is president and CEO of Y Combinator. He was a partner at Y Combinator from 2011 to 2015, where he built key parts of the YC experience for founders ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current leader of Y Combinator is Garry Tan, and the most successful companies in their portfolio include Snapdocs and Airbnb.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current leader of Y Combinator is Garry Tan, and the most successful companies in their portfolio include Snapdocs and Airbnb.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"Who is the current leader of Ycombinator? What are the most successful companies on the portfolio?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone \n",
    "index = pinecone.Index(\"mergers-and-acqs\")\n",
    "index_description = pinecone.describe_index(\"mergers-and-acqs\")\n",
    "index_stats_response = index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_stats_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from the PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfFileReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(reader.numPages):\n",
    "            text += reader.getPage(page_num).extractText()\n",
    "    return text\n",
    "\n",
    "def get_all_pdf_files_in_directory(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\"\n",
    "pdf_files = get_all_pdf_files_in_directory(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "pdf_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 15:30:53.843189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 15:30:54.633795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading model_final.pth: 100%|ââââââââââ| 330M/330M [00:30<00:00, 10.8MB/s] \n",
      "Downloading (â¦)50_FPN_3x/config.yml: 100%|ââââââââââ| 5.37k/5.37k [00:00<00:00, 5.59MB/s]\n"
     ]
    },
    {
     "ename": "TesseractNotFoundError",
     "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py:255\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     proc \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msubprocess_args())\n\u001b[1;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/international/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    972\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    973\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    974\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    975\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    976\u001b[0m                         errread, errwrite,\n\u001b[1;32m    977\u001b[0m                         restore_signals,\n\u001b[1;32m    978\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    979\u001b[0m                         start_new_session)\n\u001b[1;32m    980\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/international/lib/python3.10/subprocess.py:1847\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1846\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1847\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1848\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tesseract'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bnr_report_reader \u001b[39m=\u001b[39m UnstructuredPDFLoader(\u001b[39m\"\u001b[39m\u001b[39mdata/Annual_Report_2021_22_Web_English_Versio.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bnr_report_reader_data \u001b[39m=\u001b[39m bnr_report_reader\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m      4\u001b[0m \u001b[39m#embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m#llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# conversation = ConversationChain(llm=llm, verbose=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/international/lib/python3.10/site-packages/langchain/document_loaders/unstructured.py:61\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_elements()\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39melements\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     63\u001b[0m         docs: List[Document] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/international/lib/python3.10/site-packages/langchain/document_loaders/pdf.py:22\u001b[0m, in \u001b[0;36mUnstructuredPDFLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_elements\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List:\n\u001b[1;32m     20\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39munstructured\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpartition\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpdf\u001b[39;00m \u001b[39mimport\u001b[39;00m partition_pdf\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m partition_pdf(filename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munstructured_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured/partition/pdf.py:50\u001b[0m, in \u001b[0;36mpartition_pdf\u001b[0;34m(filename, file, url, template, token, include_page_breaks, strategy, encoding)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parses a pdf document into a list of interpreted elements.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39m    The encoding method used to decode the text input. If None, utf-8 will be used.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m exactly_one(filename\u001b[39m=\u001b[39mfilename, file\u001b[39m=\u001b[39mfile)\n\u001b[0;32m---> 50\u001b[0m \u001b[39mreturn\u001b[39;00m partition_pdf_or_image(\n\u001b[1;32m     51\u001b[0m     filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m     52\u001b[0m     file\u001b[39m=\u001b[39;49mfile,\n\u001b[1;32m     53\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m     54\u001b[0m     template\u001b[39m=\u001b[39;49mtemplate,\n\u001b[1;32m     55\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m     56\u001b[0m     include_page_breaks\u001b[39m=\u001b[39;49minclude_page_breaks,\n\u001b[1;32m     57\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m     58\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m     59\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured/partition/pdf.py:102\u001b[0m, in \u001b[0;36mpartition_pdf_or_image\u001b[0;34m(filename, file, url, template, token, is_image, include_page_breaks, strategy, encoding)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    101\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m         layout_elements \u001b[39m=\u001b[39m _partition_pdf_or_image_local(\n\u001b[1;32m    103\u001b[0m             filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m    104\u001b[0m             file\u001b[39m=\u001b[39;49mfile,\n\u001b[1;32m    105\u001b[0m             template\u001b[39m=\u001b[39;49mout_template,\n\u001b[1;32m    106\u001b[0m             is_image\u001b[39m=\u001b[39;49mis_image,\n\u001b[1;32m    107\u001b[0m             include_page_breaks\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    108\u001b[0m         )\n\u001b[1;32m    110\u001b[0m \u001b[39melif\u001b[39;00m strategy \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfast\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m fallback_to_fast:\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m _partition_pdf_with_pdfminer(\n\u001b[1;32m    112\u001b[0m         filename\u001b[39m=\u001b[39mfilename,\n\u001b[1;32m    113\u001b[0m         file\u001b[39m=\u001b[39mfile,\n\u001b[1;32m    114\u001b[0m         include_page_breaks\u001b[39m=\u001b[39minclude_page_breaks,\n\u001b[1;32m    115\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m    116\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured/partition/pdf.py:174\u001b[0m, in \u001b[0;36m_partition_pdf_or_image_local\u001b[0;34m(filename, file, template, is_image, include_page_breaks)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThere was a problem importing unstructured_inference module - it may not be installed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorrectly... try running pip install unstructured[local-inference] if you installed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe unstructured library as a package. If you cloned the unstructured repository, try \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrunning make install-local-inference from the root directory of the repository.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    171\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    173\u001b[0m layout \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 174\u001b[0m     process_file_with_model(filename, template, is_image\u001b[39m=\u001b[39;49mis_image)\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;00m process_data_with_model(file, template, is_image\u001b[39m=\u001b[39mis_image)\n\u001b[1;32m    177\u001b[0m )\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m document_to_element_list(layout, include_page_breaks\u001b[39m=\u001b[39minclude_page_breaks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:239\u001b[0m, in \u001b[0;36mprocess_file_with_model\u001b[0;34m(filename, model_name, is_image, ocr_strategy, fixed_layouts, extract_tables)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Processes pdf file with name filename into a DocumentLayout by using a model identified by\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mmodel_name.\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m model \u001b[39m=\u001b[39m get_model(model_name)\n\u001b[1;32m    234\u001b[0m layout \u001b[39m=\u001b[39m (\n\u001b[1;32m    235\u001b[0m     DocumentLayout\u001b[39m.\u001b[39mfrom_image_file(\n\u001b[1;32m    236\u001b[0m         filename, model\u001b[39m=\u001b[39mmodel, ocr_strategy\u001b[39m=\u001b[39mocr_strategy, extract_tables\u001b[39m=\u001b[39mextract_tables\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m is_image\n\u001b[0;32m--> 239\u001b[0m     \u001b[39melse\u001b[39;00m DocumentLayout\u001b[39m.\u001b[39;49mfrom_file(\n\u001b[1;32m    240\u001b[0m         filename,\n\u001b[1;32m    241\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    242\u001b[0m         ocr_strategy\u001b[39m=\u001b[39;49mocr_strategy,\n\u001b[1;32m    243\u001b[0m         fixed_layouts\u001b[39m=\u001b[39;49mfixed_layouts,\n\u001b[1;32m    244\u001b[0m         extract_tables\u001b[39m=\u001b[39;49mextract_tables,\n\u001b[1;32m    245\u001b[0m     )\n\u001b[1;32m    246\u001b[0m )\n\u001b[1;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m layout\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:72\u001b[0m, in \u001b[0;36mDocumentLayout.from_file\u001b[0;34m(cls, filename, model, fixed_layouts, ocr_strategy, extract_tables)\u001b[0m\n\u001b[1;32m     68\u001b[0m     fixed_layouts \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m layouts]\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m image, layout, fixed_layout \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(images, layouts, fixed_layouts):\n\u001b[1;32m     70\u001b[0m     \u001b[39m# NOTE(robinson) - In the future, maybe we detect the page number and default\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[39m# to the index if it is not detected\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     page \u001b[39m=\u001b[39m PageLayout\u001b[39m.\u001b[39;49mfrom_image(\n\u001b[1;32m     73\u001b[0m         image,\n\u001b[1;32m     74\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     75\u001b[0m         layout\u001b[39m=\u001b[39;49mlayout,\n\u001b[1;32m     76\u001b[0m         ocr_strategy\u001b[39m=\u001b[39;49mocr_strategy,\n\u001b[1;32m     77\u001b[0m         fixed_layout\u001b[39m=\u001b[39;49mfixed_layout,\n\u001b[1;32m     78\u001b[0m         extract_tables\u001b[39m=\u001b[39;49mextract_tables,\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     80\u001b[0m     pages\u001b[39m.\u001b[39mappend(page)\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_pages(pages)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:193\u001b[0m, in \u001b[0;36mPageLayout.from_image\u001b[0;34m(cls, image, model, layout, ocr_strategy, extract_tables, fixed_layout)\u001b[0m\n\u001b[1;32m    184\u001b[0m page \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[1;32m    185\u001b[0m     number\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    186\u001b[0m     image\u001b[39m=\u001b[39mimage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m     extract_tables\u001b[39m=\u001b[39mextract_tables,\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m fixed_layout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     page\u001b[39m.\u001b[39;49mget_elements()\n\u001b[1;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     page\u001b[39m.\u001b[39melements \u001b[39m=\u001b[39m page\u001b[39m.\u001b[39mget_elements_from_layout(fixed_layout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:147\u001b[0m, in \u001b[0;36mPageLayout.get_elements\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39m# NOTE(mrobinson) - We'll want make this model inference step some kind of\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39m# remote call in the future.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m inferred_layout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage)\n\u001b[0;32m--> 147\u001b[0m elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_elements_from_layout(inferred_layout)\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melements \u001b[39m=\u001b[39m elements\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:159\u001b[0m, in \u001b[0;36mPageLayout.get_elements_from_layout\u001b[0;34m(self, layout)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m# NOTE(robinson) - This orders the page from top to bottom. We'll need more\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m# sophisticated ordering logic for more complicated layouts.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m layout\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m element: element\u001b[39m.\u001b[39my1)\n\u001b[0;32m--> 159\u001b[0m elements \u001b[39m=\u001b[39m [\n\u001b[1;32m    160\u001b[0m     get_element_from_block(\n\u001b[1;32m    161\u001b[0m         e, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mocr_strategy, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_tables\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m layout\n\u001b[1;32m    164\u001b[0m ]\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m elements\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:160\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m# NOTE(robinson) - This orders the page from top to bottom. We'll need more\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m# sophisticated ordering logic for more complicated layouts.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m layout\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m element: element\u001b[39m.\u001b[39my1)\n\u001b[1;32m    159\u001b[0m elements \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 160\u001b[0m     get_element_from_block(\n\u001b[1;32m    161\u001b[0m         e, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mocr_strategy, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_tables\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m layout\n\u001b[1;32m    164\u001b[0m ]\n\u001b[1;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m elements\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:282\u001b[0m, in \u001b[0;36mget_element_from_block\u001b[0;34m(block, image, pdf_objects, ocr_strategy, extract_tables)\u001b[0m\n\u001b[1;32m    280\u001b[0m     text \u001b[39m=\u001b[39m interprete_table_block(block, image)\n\u001b[1;32m    281\u001b[0m \u001b[39melif\u001b[39;00m pdf_objects \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     text \u001b[39m=\u001b[39m aggregate_by_block(block, image, pdf_objects, ocr_strategy)\n\u001b[1;32m    283\u001b[0m \u001b[39melif\u001b[39;00m image \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     \u001b[39m# We don't have anything to go on but the image itself, so we use OCR\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     text \u001b[39m=\u001b[39m ocr(block, image)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:307\u001b[0m, in \u001b[0;36maggregate_by_block\u001b[0;34m(text_region, image, pdf_objects, ocr_strategy)\u001b[0m\n\u001b[1;32m    305\u001b[0m image_objects \u001b[39m=\u001b[39m [obj \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m pdf_objects \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, ImageTextRegion)]\n\u001b[1;32m    306\u001b[0m \u001b[39mif\u001b[39;00m image \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m needs_ocr(text_region, word_objects, image_objects, ocr_strategy):\n\u001b[0;32m--> 307\u001b[0m     text \u001b[39m=\u001b[39m ocr(text_region, image)\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     filtered_blocks \u001b[39m=\u001b[39m [obj \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m pdf_objects \u001b[39mif\u001b[39;00m obj\u001b[39m.\u001b[39mis_in(text_region, error_margin\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unstructured_inference/inference/layout.py:336\u001b[0m, in \u001b[0;36mocr\u001b[0;34m(text_block, image)\u001b[0m\n\u001b[1;32m    334\u001b[0m padded_block \u001b[39m=\u001b[39m text_block\u001b[39m.\u001b[39mpad(\u001b[39m12\u001b[39m)\n\u001b[1;32m    335\u001b[0m cropped_image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mcrop((padded_block\u001b[39m.\u001b[39mx1, padded_block\u001b[39m.\u001b[39my1, padded_block\u001b[39m.\u001b[39mx2, padded_block\u001b[39m.\u001b[39my2))\n\u001b[0;32m--> 336\u001b[0m \u001b[39mreturn\u001b[39;00m tesseract\u001b[39m.\u001b[39;49mocr_agent\u001b[39m.\u001b[39;49mdetect(cropped_image)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/layoutparser/ocr/tesseract_agent.py:122\u001b[0m, in \u001b[0;36mTesseractAgent.detect\u001b[0;34m(self, image, return_response, return_only_text, agg_output_level)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect\u001b[39m(\n\u001b[1;32m    103\u001b[0m     \u001b[39mself\u001b[39m, image, return_response\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, return_only_text\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, agg_output_level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    104\u001b[0m ):\n\u001b[1;32m    105\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Send the input image for OCR.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \n\u001b[1;32m    107\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m            specified aggregation level. Defaults to `None`.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_detect(image)\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m return_response:\n\u001b[1;32m    125\u001b[0m         \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/layoutparser/ocr/tesseract_agent.py:89\u001b[0m, in \u001b[0;36mTesseractAgent._detect\u001b[0;34m(self, img_content)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_detect\u001b[39m(\u001b[39mself\u001b[39m, img_content):\n\u001b[1;32m     88\u001b[0m     res \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 89\u001b[0m     res[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pytesseract\u001b[39m.\u001b[39;49mimage_to_string(\n\u001b[1;32m     90\u001b[0m         img_content, lang\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlang, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfigs\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     92\u001b[0m     _data \u001b[39m=\u001b[39m pytesseract\u001b[39m.\u001b[39mimage_to_data(img_content, lang\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigs)\n\u001b[1;32m     93\u001b[0m     res[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m     94\u001b[0m         io\u001b[39m.\u001b[39mStringIO(_data),\n\u001b[1;32m     95\u001b[0m         quoting\u001b[39m=\u001b[39mcsv\u001b[39m.\u001b[39mQUOTE_NONE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m         converters\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m},\n\u001b[1;32m     99\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py:423\u001b[0m, in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    421\u001b[0m args \u001b[39m=\u001b[39m [image, \u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m--> 423\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    424\u001b[0m     Output\u001b[39m.\u001b[39;49mBYTES: \u001b[39mlambda\u001b[39;49;00m: run_and_get_output(\u001b[39m*\u001b[39;49m(args \u001b[39m+\u001b[39;49m [\u001b[39mTrue\u001b[39;49;00m])),\n\u001b[1;32m    425\u001b[0m     Output\u001b[39m.\u001b[39;49mDICT: \u001b[39mlambda\u001b[39;49;00m: {\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m: run_and_get_output(\u001b[39m*\u001b[39;49margs)},\n\u001b[1;32m    426\u001b[0m     Output\u001b[39m.\u001b[39;49mSTRING: \u001b[39mlambda\u001b[39;49;00m: run_and_get_output(\u001b[39m*\u001b[39;49margs),\n\u001b[1;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py:426\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    421\u001b[0m args \u001b[39m=\u001b[39m [image, \u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m    423\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    424\u001b[0m     Output\u001b[39m.\u001b[39mBYTES: \u001b[39mlambda\u001b[39;00m: run_and_get_output(\u001b[39m*\u001b[39m(args \u001b[39m+\u001b[39m [\u001b[39mTrue\u001b[39;00m])),\n\u001b[1;32m    425\u001b[0m     Output\u001b[39m.\u001b[39mDICT: \u001b[39mlambda\u001b[39;00m: {\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m: run_and_get_output(\u001b[39m*\u001b[39margs)},\n\u001b[0;32m--> 426\u001b[0m     Output\u001b[39m.\u001b[39mSTRING: \u001b[39mlambda\u001b[39;00m: run_and_get_output(\u001b[39m*\u001b[39;49margs),\n\u001b[1;32m    427\u001b[0m }[output_type]()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py:288\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mwith\u001b[39;00m save(image) \u001b[39mas\u001b[39;00m (temp_name, input_filename):\n\u001b[1;32m    278\u001b[0m     kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    279\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput_filename\u001b[39m\u001b[39m'\u001b[39m: input_filename,\n\u001b[1;32m    280\u001b[0m         \u001b[39m'\u001b[39m\u001b[39moutput_filename_base\u001b[39m\u001b[39m'\u001b[39m: temp_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    286\u001b[0m     }\n\u001b[0;32m--> 288\u001b[0m     run_tesseract(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkwargs[\u001b[39m'\u001b[39m\u001b[39moutput_filename_base\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mextsep\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mextension\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m output_file:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytesseract/pytesseract.py:260\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m         \u001b[39mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[1;32m    262\u001b[0m \u001b[39mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[39mas\u001b[39;00m error_string:\n\u001b[1;32m    263\u001b[0m     \u001b[39mif\u001b[39;00m proc\u001b[39m.\u001b[39mreturncode:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m: tesseract is not installed or it's not in your PATH. See README file for more information."
     ]
    }
   ],
>>>>>>> 12b58b3 (update notebook)
   "source": [
    "bnr_report_reader = UnstructuredPDFLoader(\"data/Annual_Report_2021_22_Web_English_Versio.pdf\")\n",
    "bnr_report_reader_data = bnr_report_reader.load()\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_report_reader_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(bnr_report_reader_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/Annual_Report_2021_22_Web_English_Versio.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a name for the new index\n",
    "simple_index_name = 'stocks-trends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the index with the same name already exists\n",
    "if simple_index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(simple_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new index\n",
    "pinecone.create_index(name=simple_index_name, dimension=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nlp\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_named_entities(text_batch):\n",
    "    # extract named entities using the NER pipeline\n",
    "    extracted_batch = nlp(text_batch)\n",
    "    entities = []\n",
    "    # loop through the results and only select the entity names\n",
    "    for text in extracted_batch:\n",
    "        ne = [entity[\"word\"] for entity in text]\n",
    "        entities.append(ne)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"pinecone-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\"example-index\", dimension=128, metric=\"euclidean\", pods=4, pod_type=\"s1.x1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\"example-index\", dimension=128, source_collection=\"example-collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.configure_index(\"my_index\", pod_type=\"s1.x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"example-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.configure_index(\"example-index\", replicas=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Define retriever\n",
    "retriever = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# Define index\n",
    "index = pinecone.Index()\n",
    "\n",
    "def search_pinecone(query):\n",
    "    # extract named entities from the query\n",
    "    ne = extract_named_entities([query])[0]\n",
    "    # create embeddings for the query\n",
    "    xq = retriever.encode(query).tolist()\n",
    "    # query the pinecone index while applying named entity filter\n",
    "    xc = index.query(xq, top_k=10, include_metadata=True, filter={\"named_entities\": {\"$in\": ne}})\n",
    "    # extract article titles from the search result\n",
    "    r = [x[\"metadata\"][\"title\"] for x in xc[\"matches\"]]\n",
    "    return pprint({\"Extracted Named Entities\": ne, \"Result\": r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
    "docs = faiss_index.similarity_search(\"What are the top economic challenges facing Rwanda?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(pages)\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(api_key=pinecone_api_key)\n",
    "\n",
    "pinecone.create_index(\"national_bank_index\", dimension=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=\"YOUR_API_KEY\", environment=\"YOUR_ENVIRONMENT\")\n",
    "index = pinecone.Index(\"example-index\")\n",
    "\n",
    "index_stats_response = index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client()\n",
    "\n",
    "# create a new index \n",
    "index = client.create_index(\"bnr_index\")\n",
    "\n",
    "# add documents to the index\n",
    "for text in texts:\n",
    "    index.add_document(text)\n",
    "\n",
    "# search for similar documents  \n",
    "results = index.search(\"What are the top economic challenges facing Rwanda?\", k=2)\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(api_key=pinecone_api_key)\n",
    "index = pinecone.Index(\"example-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_config = {'indexed': ['color']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pinecone to implement a vector store \n",
    "pinecone_index = Pinecone(index_name=\"example-index\", metadata_config=metadata_config)\n",
    "\n",
    "# Use OpenAI to implement an embedding model\n",
    "openai_embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Use Weaviate to implement a vector store  \n",
    "\n",
    "weaviate_index = Weaviate(\"http://localhost:8080\", \"bnr_index\")\n",
    "\n",
    "# Use FAISS to implement a vector store\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings(openai_api_key=openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use approximate nearest neighbor search to find similar documents\n",
    "docs = faiss_index.similarity_search(\"What are the top economic challenges facing Rwanda?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

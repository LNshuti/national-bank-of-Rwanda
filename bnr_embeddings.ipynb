{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings \n",
    "from langchain.text_splitter import CharacterTextSplitter \n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate\n",
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Import PyPDF2\n",
    "import PyPDF2\n",
    "import numpy as np \n",
    "import torch\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"dslim/bert-base-NER\"\n",
    "\n",
    "# load the tokenizer from huggingface\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id\n",
    ")\n",
    "# load the NER model from huggingface\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_id\n",
    ")\n",
    "# load the tokenizer and model into a NER pipeline\n",
    "nlp = pipeline(\n",
    "    \"ner\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"max\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# Load openai api key \n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Load Pinecone API key \n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "# Load pinecode api env \n",
    "pinecone_api_env = os.environ.get('PINECONE_API_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation destinations for someone who likes to eat dessert?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"dessert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France - Home of the famous patisseries such as Laduree with its signature macarons and Pierre Herme's decadent cakes.\n",
      "\n",
      "2. Tokyo, Japan - With an ever-growing range of interesting and complex desserts from fluffy souffles to mochi ice cream, Tokyo is a great destination for dessert lovers.\n",
      "\n",
      "3. New York City, United States - A seemingly never-ending array of dessert spots, from the classic cronuts to inventive ice cream flavors, NYC has something for everyone.\n",
      "\n",
      "4. Milan, Italy - An embarrassment of riches when it comes to desserts, Milan offers traditional favorites like gelato and Tiramisu, as well as modern takes on traditional cakes and pastries.\n",
      "\n",
      "5. Vienna, Austria - Famous for its Sachertorte and apple strudel, Vienna has a deep history of decadent desserts to explore.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"dessert\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Costa Rica - known for its delicious tropical fruits such as papayas, pineapples, and bananas.\n",
      "\n",
      "2. India - expore the diverse culinary traditions of India and you'll find an abundance of sweet, juicy tropical fruits like Mangos and Guavas.\n",
      "\n",
      "3. Brazil - taste all the exotic fruits such as CupuaÃ§u, Cherimoyas, and Tomates de Arvobia.\n",
      "\n",
      "4. Thailand - enjoy an array of amazing fruits like mangosteen, Thai dragonfruit, and rambutan.\n",
      "\n",
      "5. Hawaii - savor the sweet taste of fresh pineapples, starfruit, and lychees.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"fruit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (2.4.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from google-search-results) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in some tools to use\n",
    "\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"...\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's initialize an agent with:\n",
    "# 1. The tools\n",
    "# 2. The language model\n",
    "# 3. The type of agent we want to use.\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Y Combinator is a venture capital firm, so I need to research their leaders and successful companies.\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for a website that lists Y Combinator information\n",
      "Action: Search\n",
      "Action Input: Ycombinator website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. ... Twice a year we invest $500,000 per company in a large number of startups. We work ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The website looks like it has the information I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Maybe I can find the website on a venture capital resource site\n",
      "Action: Search\n",
      "Action Input: venture capital website Ycombinator\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. Twice a year we invest $500,000 per company in a large number of startups.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the right resource\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should check Y Combinator's own website\n",
      "Action: Search\n",
      "Action Input: Ycombinator website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. ... Twice a year we invest $500,000 per company in a large number of startups. We work ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the resource I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership, successful Ycombinator companies\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Maybe a search for the leadership page of Y Combinator will provide what I'm looking for\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership page\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFounder & CEO Aaron King expertly built Snapdocs through volatile market conditions and with minimal outside funding into the mortgage industry's leading ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The leadership page looks to contain what I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGarry Tan is president and CEO of Y Combinator. He was a partner at Y Combinator from 2011 to 2015, where he built key parts of the YC experience for founders ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current leader of Y Combinator is Garry Tan, and the most successful companies in their portfolio include Snapdocs and Airbnb.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current leader of Y Combinator is Garry Tan, and the most successful companies in their portfolio include Snapdocs and Airbnb.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"Who is the current leader of Ycombinator? What are the most successful companies on the portfolio?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone \n",
    "index = pinecone.Index(\"mergers-and-acqs\")\n",
    "index_description = pinecone.describe_index(\"mergers-and-acqs\")\n",
    "index_stats_response = index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_stats_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from the PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfFileReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(reader.numPages):\n",
    "            text += reader.getPage(page_num).extractText()\n",
    "    return text\n",
    "\n",
    "def get_all_pdf_files_in_directory(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pinecone\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\"\n",
    "pdf_files = get_all_pdf_files_in_directory(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_report_reader = UnstructuredPDFLoader(\"data/Annual_Report_2021_22_Web_English_Versio.pdf\")\n",
    "bnr_report_reader_data = bnr_report_reader.load()\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_report_reader_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(bnr_report_reader_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"data/Annual_Report_2021_22_Web_English_Versio.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a name for the new index\n",
    "simple_index_name = 'stocks-trends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the index with the same name already exists\n",
    "if simple_index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(simple_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new index\n",
    "pinecone.create_index(name=simple_index_name, dimension=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nlp\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_named_entities(text_batch):\n",
    "    # extract named entities using the NER pipeline\n",
    "    extracted_batch = nlp(text_batch)\n",
    "    entities = []\n",
    "    # loop through the results and only select the entity names\n",
    "    for text in extracted_batch:\n",
    "        ne = [entity[\"word\"] for entity in text]\n",
    "        entities.append(ne)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"pinecone-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\"example-index\", dimension=128, metric=\"euclidean\", pods=4, pod_type=\"s1.x1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.create_index(\"example-index\", dimension=128, source_collection=\"example-collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.configure_index(\"my_index\", pod_type=\"s1.x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"example-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.configure_index(\"example-index\", replicas=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Define retriever\n",
    "retriever = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# Define index\n",
    "index = pinecone.Index()\n",
    "\n",
    "def search_pinecone(query):\n",
    "    # extract named entities from the query\n",
    "    ne = extract_named_entities([query])[0]\n",
    "    # create embeddings for the query\n",
    "    xq = retriever.encode(query).tolist()\n",
    "    # query the pinecone index while applying named entity filter\n",
    "    xc = index.query(xq, top_k=10, include_metadata=True, filter={\"named_entities\": {\"$in\": ne}})\n",
    "    # extract article titles from the search result\n",
    "    r = [x[\"metadata\"][\"title\"] for x in xc[\"matches\"]]\n",
    "    return pprint({\"Extracted Named Entities\": ne, \"Result\": r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
    "docs = faiss_index.similarity_search(\"What are the top economic challenges facing Rwanda?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(pages)\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(api_key=pinecone_api_key)\n",
    "\n",
    "pinecone.create_index(\"national_bank_index\", dimension=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=\"YOUR_API_KEY\", environment=\"YOUR_ENVIRONMENT\")\n",
    "index = pinecone.Index(\"example-index\")\n",
    "\n",
    "index_stats_response = index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client()\n",
    "\n",
    "# create a new index \n",
    "index = client.create_index(\"bnr_index\")\n",
    "\n",
    "# add documents to the index\n",
    "for text in texts:\n",
    "    index.add_document(text)\n",
    "\n",
    "# search for similar documents  \n",
    "results = index.search(\"What are the top economic challenges facing Rwanda?\", k=2)\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(api_key=pinecone_api_key)\n",
    "index = pinecone.Index(\"example-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_config = {'indexed': ['color']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pinecone to implement a vector store \n",
    "pinecone_index = Pinecone(index_name=\"example-index\", metadata_config=metadata_config)\n",
    "\n",
    "# Use OpenAI to implement an embedding model\n",
    "openai_embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Use Weaviate to implement a vector store  \n",
    "\n",
    "weaviate_index = Weaviate(\"http://localhost:8080\", \"bnr_index\")\n",
    "\n",
    "# Use FAISS to implement a vector store\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings(openai_api_key=openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use approximate nearest neighbor search to find similar documents\n",
    "docs = faiss_index.similarity_search(\"What are the top economic challenges facing Rwanda?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings \n",
    "from langchain.text_splitter import CharacterTextSplitter \n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate\n",
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Pinecone.__init__() missing 3 required positional arguments: 'index', 'embedding_function', and 'text_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m embeddings \u001b[39m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m      4\u001b[0m \u001b[39m# Load Pinecone vector store\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m vector_store \u001b[39m=\u001b[39m Pinecone()\n\u001b[1;32m      7\u001b[0m \u001b[39m# Load the conversation chain\u001b[39;00m\n\u001b[1;32m      8\u001b[0m chain \u001b[39m=\u001b[39m ConversationChain(embeddings\u001b[39m=\u001b[39membeddings, vector_store\u001b[39m=\u001b[39mvector_store)  \n",
      "\u001b[0;31mTypeError\u001b[0m: Pinecone.__init__() missing 3 required positional arguments: 'index', 'embedding_function', and 'text_key'"
     ]
    }
   ],
   "source": [
    "# Load sentence transformer model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load Pinecone vector store\n",
    "vector_store = Pinecone()\n",
    "\n",
    "# Load the conversation chain\n",
    "chain = ConversationChain(embeddings=embeddings, vector_store=vector_store)  \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 19,
>>>>>>> fc35cdd (add langchain agents)
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# Load openai api key \n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Load Pinecone API key \n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "# Load pinecode api env \n",
    "pinecone_api_env = os.environ.get('PINECONE_API_ENV')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 5 vacation destinations for someone who likes to eat dessert?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"dessert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Paris, France - Home of the famous patisseries such as Laduree with its signature macarons and Pierre Herme's decadent cakes.\n",
      "\n",
      "2. Tokyo, Japan - With an ever-growing range of interesting and complex desserts from fluffy souffles to mochi ice cream, Tokyo is a great destination for dessert lovers.\n",
      "\n",
      "3. New York City, United States - A seemingly never-ending array of dessert spots, from the classic cronuts to inventive ice cream flavors, NYC has something for everyone.\n",
      "\n",
      "4. Milan, Italy - An embarrassment of riches when it comes to desserts, Milan offers traditional favorites like gelato and Tiramisu, as well as modern takes on traditional cakes and pastries.\n",
      "\n",
      "5. Vienna, Austria - Famous for its Sachertorte and apple strudel, Vienna has a deep history of decadent desserts to explore.\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"dessert\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Costa Rica - known for its delicious tropical fruits such as papayas, pineapples, and bananas.\n",
      "\n",
      "2. India - expore the diverse culinary traditions of India and you'll find an abundance of sweet, juicy tropical fruits like Mangos and Guavas.\n",
      "\n",
      "3. Brazil - taste all the exotic fruits such as CupuaÃ§u, Cherimoyas, and Tomates de Arvobia.\n",
      "\n",
      "4. Thailand - enjoy an array of amazing fruits like mangosteen, Thai dragonfruit, and rambutan.\n",
      "\n",
      "5. Hawaii - savor the sweet taste of fresh pineapples, starfruit, and lychees.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"fruit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (2.4.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from google-search-results) (2.28.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\leonce nshuti\\desktop\\portfolio\\national-bank-of-rwanda\\embed\\lib\\site-packages (from requests->google-search-results) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in some tools to use\n",
    "\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"...\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's initialize an agent with:\n",
    "# 1. The tools\n",
    "# 2. The language model\n",
    "# 3. The type of agent we want to use.\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Y Combinator is a venture capital firm, so I need to research their leaders and successful companies.\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for a website that lists Y Combinator information\n",
      "Action: Search\n",
      "Action Input: Ycombinator website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. ... Twice a year we invest $500,000 per company in a large number of startups. We work ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The website looks like it has the information I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Maybe I can find the website on a venture capital resource site\n",
      "Action: Search\n",
      "Action Input: venture capital website Ycombinator\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. Twice a year we invest $500,000 per company in a large number of startups.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the right resource\n",
      "Action: Search\n",
      "Action Input: Ycombinator leader, successful Ycombinator companies website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should check Y Combinator's own website\n",
      "Action: Search\n",
      "Action Input: Ycombinator website\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mY Combinator created a new model for funding early stage startups. ... Twice a year we invest $500,000 per company in a large number of startups. We work ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This looks like the resource I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership, successful Ycombinator companies\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good search result found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Maybe a search for the leadership page of Y Combinator will provide what I'm looking for\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership page\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFounder & CEO Aaron King expertly built Snapdocs through volatile market conditions and with minimal outside funding into the mortgage industry's leading ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The leadership page looks to contain what I need\n",
      "Action: Search\n",
      "Action Input: Ycombinator leadership\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGarry Tan is president and CEO of Y Combinator. He was a partner at Y Combinator from 2011 to 2015, where he built key parts of the YC experience for founders ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current leader of Y Combinator is Garry Tan, and the most successful companies in their portfolio include Snapdocs and Airbnb.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current leader of Y Combinator is Garry Tan, and the most successful companies in their portfolio include Snapdocs and Airbnb.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test it out!\n",
    "agent.run(\"Who is the current leader of Ycombinator? What are the most successful companies on the portfolio?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> fc35cdd (add langchain agents)
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfFileReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(reader.numPages):\n",
    "            text += reader.getPage(page_num).extractText()\n",
    "    return text\n",
    "\n",
    "def get_all_pdf_files_in_directory(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Initialize a Pinecone client\n",
    "\n",
    "pinecone.init(api_key=pinecone_api_key, api_env=pinecone_api_env)\n",
    "#help(pinecone.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a name for the new index\n",
    "new_index_name = 'semantic-text-search'\n",
    "existing_index_name = 'mergers-and-acqs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vector embeddings\n",
    "#model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\"\n",
    "pdf_files = get_all_pdf_files_in_directory(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 15:30:53.843189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 15:30:54.633795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading model_final.pth: 100%|ââââââââââ| 330M/330M [00:30<00:00, 10.8MB/s] \n",
      "Downloading (â¦)50_FPN_3x/config.yml: 100%|ââââââââââ| 5.37k/5.37k [00:00<00:00, 5.59MB/s]\n"
     ]
    }
   ],
=======
   "outputs": [],
   "source": [
    "pdf_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> fc35cdd (add langchain agents)
   "source": [
    "bnr_report_reader = UnstructuredPDFLoader(\"data/Annual_Report_2021_22_Web_English_Versio.pdf\")\n",
    "bnr_report_reader_data = bnr_report_reader.load()\n",
    "\n",
    "#embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "#llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "# conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversation = ConversationChain(llm=llm, verbose=True)\n",
    "#conversation.add(\"What is the BNR?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "faiss_index = FAISS.from_documents(bnr_report_reader_data, OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
    "docs = faiss_index.similarity_search(\"What are the top economic challenges facing Rwanda?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = TFAutoModel.from_pretrained(model_ckpt, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a name for the new index\n",
    "simple_index_name = 'nationalbank-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the index with the same name already exists\n",
    "if simple_index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(simple_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new index\n",
    "pinecone.create_index(name=simple_index_name, dimension=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"pinecone-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(text):\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [(X.text, X.label_) for X in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load SentenceTransformer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Define retriever\n",
    "retriever = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# Define index\n",
    "index = pinecone.Index()\n",
    "\n",
    "def search_pinecone(query):\n",
    "    # extract named entities from the query\n",
    "    ne = extract_named_entities([query])[0]\n",
    "    # create embeddings for the query\n",
    "    xq = retriever.encode(query).tolist()\n",
    "    # query the pinecone index while applying named entity filter\n",
    "    xc = index.query(xq, top_k=10, include_metadata=True, filter={\"named_entities\": {\"$in\": ne}})\n",
    "    # extract article titles from the search result\n",
    "    r = [x[\"metadata\"][\"title\"] for x in xc[\"matches\"]]\n",
    "    return pprint({\"Extracted Named Entities\": ne, \"Result\": r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

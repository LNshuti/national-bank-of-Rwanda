{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings \n",
    "from langchain.text_splitter import CharacterTextSplitter \n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate\n",
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# Load openai api key \n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Load Pinecone API key \n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "\n",
    "# Load pinecode api env \n",
    "pinecone_api_env = os.environ.get('PINECONE_API_ENV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfFileReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(reader.numPages):\n",
    "            text += reader.getPage(page_num).extractText()\n",
    "    return text\n",
    "\n",
    "def get_all_pdf_files_in_directory(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "# Initialize a Pinecone client\n",
    "\n",
    "pinecone.init(api_key=pinecone_api_key, api_env=pinecone_api_env)\n",
    "#help(pinecone.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a name for the new index\n",
    "new_index_name = 'semantic-text-search'\n",
    "existing_index_name = 'mergers-and-acqs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vector embeddings\n",
    "#model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"data/\"\n",
    "pdf_files = get_all_pdf_files_in_directory(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnr_report_reader = UnstructuredPDFLoader(\"data/Annual_Report_2021_22_Web_English_Versio.pdf\")\n",
    "#bnr_report_reader_data = bnr_report_reader.load()\n",
    "\n",
    "#embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "#llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "# conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.document_loaders.pdf.UnstructuredPDFLoader at 0x7f1c9d3eea40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conversation = ConversationChain(llm=llm, verbose=True)\n",
    "#conversation.add(\"What is the BNR?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bnr_report_reader_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m FAISS\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m----> 4\u001b[0m faiss_index \u001b[39m=\u001b[39m FAISS\u001b[39m.\u001b[39mfrom_documents(bnr_report_reader_data, OpenAIEmbeddings(openai_api_key\u001b[39m=\u001b[39mopenai_api_key))\n\u001b[1;32m      5\u001b[0m docs \u001b[39m=\u001b[39m faiss_index\u001b[39m.\u001b[39msimilarity_search(\u001b[39m\"\u001b[39m\u001b[39mWhat are the top economic challenges facing Rwanda?\u001b[39m\u001b[39m\"\u001b[39m, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bnr_report_reader_data' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "faiss_index = FAISS.from_documents(bnr_report_reader_data, OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
    "docs = faiss_index.similarity_search(\"What are the top economic challenges facing Rwanda?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = TFAutoModel.from_pretrained(model_ckpt, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a name for the new index\n",
    "simple_index_name = 'nationalbank-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the index with the same name already exists\n",
    "if simple_index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(simple_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new index\n",
    "pinecone.create_index(name=simple_index_name, dimension=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.describe_index(\"pinecone-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_named_entities(text):\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    return [(X.text, X.label_) for X in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Define retriever\n",
    "retriever = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# Define index\n",
    "index = pinecone.Index()\n",
    "\n",
    "def search_pinecone(query):\n",
    "    # extract named entities from the query\n",
    "    ne = extract_named_entities([query])[0]\n",
    "    # create embeddings for the query\n",
    "    xq = retriever.encode(query).tolist()\n",
    "    # query the pinecone index while applying named entity filter\n",
    "    xc = index.query(xq, top_k=10, include_metadata=True, filter={\"named_entities\": {\"$in\": ne}})\n",
    "    # extract article titles from the search result\n",
    "    r = [x[\"metadata\"][\"title\"] for x in xc[\"matches\"]]\n",
    "    return pprint({\"Extracted Named Entities\": ne, \"Result\": r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
